{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input size, hidden layer size, output size\n",
    "D_i, D_k, D_o = 100, 4000, 50\n",
    "# create model with two hidden layers\n",
    "model = nn.Sequential(\n",
    "       nn.Linear(D_i, D_k),\n",
    "       nn.ReLU(),\n",
    "       nn.Linear(D_k, D_k),\n",
    "       nn.ReLU(),\n",
    "       nn.Linear(D_k, D_o)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/khg6jj9s4_b0lqrt24p4bvs00000gn/T/ipykernel_10060/3350313036.py:4: FutureWarning: `nn.init.kaiming_uniform` is now deprecated in favor of `nn.init.kaiming_uniform_`.\n",
      "  nn.init.kaiming_uniform(layer_in.weight)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=100, out_features=4000, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=4000, out_features=4000, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=4000, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# He initialization of weights\n",
    "def weights_init(layer_in):\n",
    "    if isinstance(layer_in, nn.Linear):\n",
    "        nn.init.kaiming_uniform(layer_in.weight)\n",
    "        #layer_in.weight.data.fill_(-10.0)\n",
    "        #layer_in.bias.data.fill_(-100.0)\n",
    "model.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose least squares loss function\n",
    "criterion = nn.MSELoss()\n",
    "# construct SGD optimizer and initialize learning rate and momentum\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1, momentum=0.9)\n",
    "# object that decreases learning rate by half every 10 epochs\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 100 random data points and store in data loader class\n",
    "x = torch.randn(1000, D_i).to(device)\n",
    "y = torch.randn(1000, D_o).to(device)\n",
    "data_loader = DataLoader(TensorDataset(x,y), batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the dataset 100 times\n",
    "def train():\n",
    "    for epoch in range(10):\n",
    "        epoch_loss = 0.0\n",
    "        # loop over batches\n",
    "        for i, data in enumerate(data_loader):\n",
    "            # retrieve inputs and labels for this batch\n",
    "            x_batch, y_batch = data\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass\n",
    "            pred = model(x_batch)\n",
    "            loss = criterion(pred, y_batch)\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "            # SGD update\n",
    "            optimizer.step()\n",
    "            # update statistics\n",
    "            epoch_loss += loss.item()\n",
    "        # print error\n",
    "        print(f'Epoch {epoch:5d}, loss {epoch_loss:.3f}')\n",
    "        # tell scheduler to consider updating learning rate\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0, loss 99.913\n",
      "Epoch     1, loss 99.913\n",
      "Epoch     2, loss 99.913\n",
      "Epoch     3, loss 99.913\n",
      "Epoch     4, loss 99.913\n",
      "Epoch     5, loss 99.913\n",
      "Epoch     6, loss 99.913\n",
      "Epoch     7, loss 99.913\n",
      "Epoch     8, loss 99.913\n",
      "Epoch     9, loss 99.913\n",
      "Epoch     0, loss 99.912\n",
      "Epoch     1, loss 99.912\n",
      "Epoch     2, loss 99.912\n",
      "Epoch     3, loss 99.912\n",
      "Epoch     4, loss 99.912\n",
      "Epoch     5, loss 99.912\n",
      "Epoch     6, loss 99.912\n",
      "Epoch     7, loss 99.912\n",
      "Epoch     8, loss 99.912\n",
      "Epoch     9, loss 99.912\n",
      "Epoch     0, loss 99.912\n",
      "Epoch     1, loss 99.912\n",
      "Epoch     2, loss 99.912\n",
      "Epoch     3, loss 99.912\n",
      "Epoch     4, loss 99.912\n",
      "Epoch     5, loss 99.912\n",
      "Epoch     6, loss 99.912\n",
      "Epoch     7, loss 99.912\n",
      "Epoch     8, loss 99.912\n",
      "Epoch     9, loss 99.912\n",
      "Epoch     0, loss 99.912\n",
      "Epoch     1, loss 99.912\n",
      "Epoch     2, loss 99.912\n",
      "Epoch     3, loss 99.912\n",
      "Epoch     4, loss 99.912\n",
      "Epoch     5, loss 99.912\n",
      "Epoch     6, loss 99.912\n",
      "Epoch     7, loss 99.912\n",
      "Epoch     8, loss 99.912\n",
      "Epoch     9, loss 99.912\n",
      "Epoch     0, loss 99.912\n",
      "Epoch     1, loss 99.912\n",
      "Epoch     2, loss 99.912\n",
      "Epoch     3, loss 99.912\n",
      "Epoch     4, loss 99.912\n",
      "Epoch     5, loss 99.912\n",
      "Epoch     6, loss 99.912\n",
      "Epoch     7, loss 99.912\n",
      "Epoch     8, loss 99.912\n",
      "Epoch     9, loss 99.912\n",
      "Epoch     0, loss 99.912\n",
      "Epoch     1, loss 99.912\n",
      "Epoch     2, loss 99.912\n",
      "Epoch     3, loss 99.912\n",
      "Epoch     4, loss 99.912\n",
      "Epoch     5, loss 99.912\n",
      "Epoch     6, loss 99.912\n",
      "Epoch     7, loss 99.912\n",
      "Epoch     8, loss 99.912\n",
      "Epoch     9, loss 99.912\n",
      "Epoch     0, loss 99.912\n",
      "Epoch     1, loss 99.912\n",
      "Epoch     2, loss 99.912\n",
      "Epoch     3, loss 99.912\n",
      "Epoch     4, loss 99.912\n",
      "Epoch     5, loss 99.912\n",
      "Epoch     6, loss 99.912\n",
      "Epoch     7, loss 99.912\n",
      "Epoch     8, loss 99.912\n",
      "Epoch     9, loss 99.912\n",
      "Epoch     0, loss 99.912\n",
      "Epoch     1, loss 99.912\n",
      "Epoch     2, loss 99.912\n",
      "Epoch     3, loss 99.912\n",
      "Epoch     4, loss 99.912\n",
      "Epoch     5, loss 99.912\n",
      "Epoch     6, loss 99.912\n",
      "Epoch     7, loss 99.912\n",
      "Epoch     8, loss 99.912\n",
      "Epoch     9, loss 99.912\n",
      "14.1 s ± 24.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
